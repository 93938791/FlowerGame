"""
ä¸‹è½½æœåŠ¡ - å¤„ç†æ¸¸æˆç‰ˆæœ¬ã€åŠ è½½å™¨ã€æ¨¡ç»„ç­‰èµ„æºçš„ä¸‹è½½
"""
import os
import json
import shutil
import time
import threading
import asyncio
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Optional, Dict, List, Callable, Tuple
from utils.logger import Logger
from service.cache import ConfigCache

# å¯¼å…¥æ‹†åˆ†åçš„æ¨¡å—
from .download_config import DownloadConfig
from .async_http2_downloader import AsyncHTTP2Downloader
from .download_thread import DownloadThread
from .mirror_utils import MirrorUtils
from .modrinth_client import ModrinthClient

# å¯¼å…¥åŠ è½½å™¨æ¨¡å—
from .loaders.fabric_loader import FabricLoader
from .loaders.forge_loader import ForgeLoader
from .loaders.neoforge_loader import NeoForgeLoader
from .loaders.optifine_loader import OptiFineLoader

logger = Logger().get_logger("DownloadService")


class DownloadService:
    """ä¸‹è½½æœåŠ¡ç±»"""
    
    def __init__(self, config: dict):
        """
        åˆå§‹åŒ–ä¸‹è½½æœåŠ¡
        
        Args:
            config: é…ç½®å­—å…¸
        """
        # åˆå§‹åŒ–é…ç½®
        self.config = DownloadConfig(config)
        
        # åˆå§‹åŒ–HTTP/2å¼‚æ­¥ä¸‹è½½å™¨
        self.async_downloader = AsyncHTTP2Downloader(self.config)
        
        # åˆå§‹åŒ–åŠ è½½å™¨
        self.fabric_loader = FabricLoader(self.config, self.async_downloader)
        self.forge_loader = ForgeLoader(self.config, self.async_downloader)
        self.neoforge_loader = NeoForgeLoader(self.config, self.async_downloader)
        self.optifine_loader = OptiFineLoader(self.config, self.async_downloader)
        
        # å½“å‰æ´»è·ƒçš„åº•å±‚ä¸‹è½½çº¿ç¨‹ï¼ˆç”¨äºå–æ¶ˆæ§åˆ¶ï¼‰
        self.current_download_thread: Optional[DownloadThread] = None
        # ä½¿ç”¨åˆ—è¡¨ä½œä¸ºå¯å˜å¼•ç”¨ï¼Œä»¥ä¾¿ ModrinthClient å¯ä»¥æ›´æ–°
        self._download_thread_ref = [None]
        
        # åˆ›å»ºé•œåƒå·¥å…·å®ä¾‹
        self.mirror_utils = MirrorUtils(self.config)
        
        # åˆå§‹åŒ–é•œåƒå¥åº·çŠ¶æ€ä¸å»¶è¿Ÿï¼ˆå¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡å¯åŠ¨ï¼‰
        logger.debug(f"[é•œåƒé…ç½®] BMCLAPIé•œåƒ: {'å¯ç”¨' if self.config.use_mirror else 'ç¦ç”¨'} | åŸŸå: {self.config.BMCLAPI_DOMAIN}")
        self.mirror_utils.init_mirror_health_async()
        
        # åŒæ­¥ modrinth_source_orderï¼ˆMirrorUtils ä¼šåœ¨åå°æ›´æ–°ï¼‰
        def _sync_modrinth_order():
            import time as time_module
            time_module.sleep(1)  # ç­‰å¾…åˆå§‹åŒ–
            # æ›´æ–° ModrinthClient çš„æºé¡ºåºï¼ˆå¦‚æœéœ€è¦ï¼‰
            pass
        threading.Thread(target=_sync_modrinth_order, daemon=True).start()
    
    def get_minecraft_versions(self) -> List[Dict]:
        """
        è·å–Minecraftç‰ˆæœ¬åˆ—è¡¨ï¼ˆæ”¯æŒé•œåƒfallbackå’Œç¼“å­˜ï¼‰
        
        Returns:
            Minecraftç‰ˆæœ¬åˆ—è¡¨
        """
        try:
            import requests
            from requests.adapters import HTTPAdapter
            from urllib3.util.retry import Retry
            
            # æ£€æŸ¥ç¼“å­˜ï¼ˆç¼“å­˜5åˆ†é’Ÿï¼‰
            cache_file = self.config.minecraft_dir / ".version_manifest_cache.json"
            cache_timeout = self.config.CACHE_TIMEOUT
            
            if cache_file.exists():
                try:
                    cache_age = time.time() - cache_file.stat().st_mtime
                    if cache_age < cache_timeout:
                        logger.debug(f"[ç‰ˆæœ¬æ¸…å•] ä½¿ç”¨ç¼“å­˜ï¼ˆç¼“å­˜å¹´é¾„: {cache_age:.1f}ç§’ï¼‰")
                        with open(cache_file, 'r', encoding='utf-8') as f:
                            cached_data = json.load(f)
                            versions = []
                            for version in cached_data.get("versions", []):
                                # è¿”å›æ‰€æœ‰ç±»å‹çš„ç‰ˆæœ¬ï¼Œä¸ä»…ä»…æ˜¯releaseç±»å‹
                                version_url = version.get("url", "")
                                original_v_url = version_url
                                version_url = self.mirror_utils.convert_to_mirror_url(version_url)
                                versions.append({
                                    "id": version.get("id"),
                                    "type": version.get("type"),
                                    "url": version_url,
                                    "original_url": original_v_url,
                                    "time": version.get("time"),
                                    "releaseTime": version.get("releaseTime")
                                })
                            logger.debug(f"[ç‰ˆæœ¬æ¸…å•] ä»ç¼“å­˜åŠ è½½ {len(versions)} ä¸ªç‰ˆæœ¬")
                            return versions
                except Exception as e:
                    logger.warning(f"[ç‰ˆæœ¬æ¸…å•] è¯»å–ç¼“å­˜å¤±è´¥: {e}ï¼Œå°†é‡æ–°ä¸‹è½½")
            
            original_url = self.config.VERSION_MANIFEST_URL
            url = self.mirror_utils.convert_to_mirror_url(original_url)
            is_mirror = url != original_url
            
            logger.debug(f"[ä¸‹è½½è¯·æ±‚] ç‰ˆæœ¬æ¸…å• | åŸå§‹: {original_url} | é•œåƒ: {url} | ä½¿ç”¨é•œåƒ: {is_mirror}")
            
            # åˆ›å»ºä¼šè¯å¯¹è±¡ï¼Œé…ç½®é‡è¯•æœºåˆ¶
            session = requests.Session()
            
            # é…ç½®é‡è¯•ç­–ç•¥
            retry_strategy = Retry(
                total=3,  # æ€»é‡è¯•æ¬¡æ•°
                status_forcelist=[429, 500, 502, 503, 504],  # é‡è¯•çš„çŠ¶æ€ç 
                backoff_factor=0.5,  # é‡è¯•é—´éš”ï¼š0.5, 1, 2ç§’
                allowed_methods=["HEAD", "GET", "OPTIONS"]  # é‡è¯•çš„æ–¹æ³•
            )
            
            # é…ç½®é€‚é…å™¨
            adapter = HTTPAdapter(max_retries=retry_strategy)
            session.mount("http://", adapter)
            session.mount("https://", adapter)
            
            # å€™é€‰URLåˆ—è¡¨
            candidate_urls = [url, original_url]
            
            # æœ€å¤šé‡è¯•3æ¬¡ï¼Œæ¯æ¬¡å°è¯•æ‰€æœ‰å€™é€‰URL
            max_retries = 3
            response = None
            
            for retry in range(max_retries):
                for idx, current_url in enumerate(candidate_urls):
                    logger.debug(f"[ä¸‹è½½è¯·æ±‚] ç‰ˆæœ¬æ¸…å• | å°è¯• {retry+1}/{max_retries} | æº {idx+1}/{len(candidate_urls)} | URL: {current_url}")
                    
                    try:
                        # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œå¤„ç†ç½‘ç»œå»¶è¿Ÿè¾ƒé«˜çš„æƒ…å†µ
                        response = session.get(
                            current_url, 
                            timeout=(10.0, 20.0),  # è¿æ¥è¶…æ—¶10ç§’ï¼Œè¯»å–è¶…æ—¶20ç§’
                            allow_redirects=True
                        )
                        response.raise_for_status()
                        logger.debug(f"[ä¸‹è½½è¯·æ±‚] ç‰ˆæœ¬æ¸…å• | è¯·æ±‚æˆåŠŸ")
                        break
                    except requests.exceptions.RequestException as e:
                        # æ•è·æ‰€æœ‰è¯·æ±‚å¼‚å¸¸
                        logger.warning(f"[ä¸‹è½½è¯·æ±‚] ç‰ˆæœ¬æ¸…å• | è¯·æ±‚å¤±è´¥: {e}")
                        # ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªURLæˆ–é‡è¯•
                        continue
                else:
                    # æ‰€æœ‰URLéƒ½å¤±è´¥äº†ï¼Œç­‰å¾…1ç§’åé‡è¯•
                    time.sleep(1)
                    continue
                # æœ‰ä¸€ä¸ªURLæˆåŠŸäº†ï¼Œè·³å‡ºå¾ªç¯
                break
            
            if not response:
                # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†
                logger.error(f"[ä¸‹è½½è¯·æ±‚] ç‰ˆæœ¬æ¸…å• | æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†ï¼Œæœ€å¤šé‡è¯• {max_retries} æ¬¡")
                return []
            
            data = response.json()
            
            # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆæ— è®ºä»å“ªä¸ªæºä¸‹è½½æˆåŠŸï¼‰
            try:
                with open(cache_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                logger.debug(f"[ç‰ˆæœ¬æ¸…å•] å·²ä¿å­˜åˆ°ç¼“å­˜: {cache_file}")
            except Exception as e:
                logger.warning(f"[ç‰ˆæœ¬æ¸…å•] ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
            
            versions = []
            for version in data.get("versions", []):
                # è¿”å›æ‰€æœ‰ç±»å‹çš„ç‰ˆæœ¬ï¼Œä¸ä»…ä»…æ˜¯releaseç±»å‹
                version_url = version.get("url", "")
                # è½¬æ¢ç‰ˆæœ¬JSONçš„URLä¸ºé•œåƒ
                original_v_url = version_url
                version_url = self.mirror_utils.convert_to_mirror_url(version_url)
                versions.append({
                    "id": version.get("id"),
                    "type": version.get("type"),
                    "url": version_url,  # å·²è½¬æ¢çš„é•œåƒURL
                    "original_url": original_v_url,  # ä¿å­˜åŸå§‹URLç”¨äºfallback
                    "time": version.get("time"),
                    "releaseTime": version.get("releaseTime")
                })
            
            logger.info(f"[ä¸‹è½½å®Œæˆ] ç‰ˆæœ¬æ¸…å• | å…±è·å– {len(versions)} ä¸ªç‰ˆæœ¬")
            return versions
            
        except Exception as e:
            logger.error(f"è·å–ç‰ˆæœ¬åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
            return []
    
    def download_minecraft_version(self, version_id: str, custom_name: Optional[str] = None, progress_callback: Optional[Callable] = None) -> bool:
        """
        ä¸‹è½½Minecraftç‰ˆæœ¬ï¼ˆä¼˜åŒ–ï¼šç›´æ¥æ„å»ºç‰ˆæœ¬JSON URLï¼Œæ— éœ€ä¸‹è½½æ•´ä¸ªç‰ˆæœ¬æ¸…å•ï¼‰
        
        Args:
            version_id: Minecraftç‰ˆæœ¬IDï¼ˆå¦‚ 1.21.10ï¼‰
            custom_name: è‡ªå®šä¹‰ç‰ˆæœ¬åç§°ï¼ˆç”¨äºç‰ˆæœ¬éš”ç¦»ï¼Œå¦‚ "551"ï¼‰ï¼Œå¦‚æœæä¾›åˆ™ä¸‹è½½åˆ° versions/{custom_name}/ ç›®å½•
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ”¯æŒå¤šä»»åŠ¡å›è°ƒæ ¼å¼ï¼šprogress_callback(current, total, status, task_id=None)
        """
        try:
            if not self.config.minecraft_dir or not self.config.minecraft_dir.exists():
                logger.error("Minecraftç›®å½•æœªè®¾ç½®æˆ–ä¸å­˜åœ¨")
                return False
            
            # ç¡®å®šç‰ˆæœ¬ç›®å½•ï¼šå¦‚æœæä¾›äº†custom_nameï¼Œä½¿ç”¨custom_nameï¼›å¦åˆ™ä½¿ç”¨version_id
            version_dir_name = custom_name if custom_name else version_id
            
            if progress_callback:
                progress_callback(0, 100, "æ­£åœ¨è·å–ç‰ˆæœ¬ä¿¡æ¯...", task_id="version_info")
            
            # ç›´æ¥ä»ç‰ˆæœ¬æ¸…å•è·å–ç‰ˆæœ¬JSON URLï¼ˆè¿™æ˜¯å”¯ä¸€å¯é çš„æ–¹å¼ï¼‰
            logger.debug(f"[ä¸‹è½½æµç¨‹] ç‰ˆæœ¬JSON ({version_id}) | æ­¥éª¤1: è·å–ç‰ˆæœ¬æ¸…å•ï¼ˆå¸¦ç¼“å­˜ï¼‰")
            versions = self.get_minecraft_versions()
            version_info = next((v for v in versions if v["id"] == version_id), None)
            
            if not version_info:
                logger.error(f"æœªæ‰¾åˆ°ç‰ˆæœ¬: {version_id}")
                return False
            
            # æ­¥éª¤2: ä¸‹è½½ç‰ˆæœ¬JSONï¼ˆä½¿ç”¨æ¸…å•ä¸­çš„URLï¼Œå·²è½¬æ¢é•œåƒï¼‰
            original_v_url = version_info.get("original_url") or version_info["url"]
            version_url = version_info["url"]
            # ç¡®ä¿URLå·²è½¬æ¢ä¸ºé•œåƒï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
            if "piston-meta.mojang.com" in version_url or "launchermeta.mojang.com" in version_url or "launcher.mojang.com" in version_url:
                version_url = self.mirror_utils.convert_to_mirror_url(version_url)
            is_mirror = version_url != original_v_url
            
            logger.debug(f"[ä¸‹è½½æµç¨‹] ç‰ˆæœ¬JSON ({version_id}) | æ­¥éª¤2: ä¸‹è½½ç‰ˆæœ¬JSON")
            logger.debug(f"[ä¸‹è½½è¯·æ±‚] ç‰ˆæœ¬JSON ({version_id}) | åŸå§‹: {original_v_url} | é•œåƒ: {version_url} | ä½¿ç”¨é•œåƒ: {is_mirror}")
            
            import requests
            response = requests.get(version_url, timeout=10)
            response.raise_for_status()
            version_data = response.json()
            
            # ä¿å­˜ç‰ˆæœ¬JSON
            version_dir = self.config.minecraft_dir / "versions" / version_dir_name
            version_dir.mkdir(parents=True, exist_ok=True)
            # JSONæ–‡ä»¶åä½¿ç”¨version_idï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰ï¼Œä½†å­˜å‚¨åœ¨version_dir_nameç›®å½•ä¸­
            version_json_path = version_dir / f"{version_id}.json"
            
            with open(version_json_path, 'w', encoding='utf-8') as f:
                json.dump(version_data, f, indent=2, ensure_ascii=False)
            
            # ä¸‹è½½å®¢æˆ·ç«¯JAR
            client_info = version_data["downloads"]["client"]
            client_jar_url = self.mirror_utils.convert_to_mirror_url(client_info["url"])
            client_sha1 = client_info.get("sha1")
            # JARæ–‡ä»¶åä½¿ç”¨version_idï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰ï¼Œä½†å­˜å‚¨åœ¨version_dir_nameç›®å½•ä¸­
            client_jar_path = version_dir / f"{version_id}.jar"
            
            if progress_callback:
                progress_callback(10, 100, "æ­£åœ¨ä¸‹è½½å®¢æˆ·ç«¯JAR...", task_id="client_jar")
            
            thread = DownloadThread(
                client_jar_url,
                client_jar_path,
                self.config.use_mirror,
                expected_sha1=client_sha1,
                mirror_converter=self.mirror_utils.convert_to_mirror_url
            )
            self.current_download_thread = thread
            self._download_thread_ref[0] = thread
            success = False
            error_msg = ""
            finished_event = threading.Event()
            
            def on_finished(s, msg):
                nonlocal success, error_msg
                success = s
                error_msg = msg
                logger.debug(f"[ä¸‹è½½å›è°ƒ] å®¢æˆ·ç«¯JAR | æˆåŠŸ: {s} | æ¶ˆæ¯: {msg}")
                finished_event.set()
            
            thread.finished.connect(on_finished)
            logger.debug(f"[ä¸‹è½½æµç¨‹] å¯åŠ¨å®¢æˆ·ç«¯JARä¸‹è½½çº¿ç¨‹ï¼Œç›®æ ‡æ–‡ä»¶: {client_jar_path}")
            thread.start()
            
            # ç­‰å¾…çº¿ç¨‹å®Œæˆï¼ŒåŒæ—¶è½®è¯¢æ£€æŸ¥æ–‡ä»¶
            logger.info(f"[ä¸‹è½½æµç¨‹] ç­‰å¾…å®¢æˆ·ç«¯JARä¸‹è½½å®Œæˆ...")
            max_wait_time = 300  # æœ€å¤š5åˆ†é’Ÿ
            check_interval = 0.5  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
            elapsed = 0
            
            while elapsed < max_wait_time:
                # æ£€æŸ¥ä¿¡å·æ˜¯å¦å·²è§¦å‘
                if finished_event.is_set():
                    logger.info(f"[ä¸‹è½½æµç¨‹] æ”¶åˆ°ä¸‹è½½å®Œæˆä¿¡å·ï¼Œsuccess={success}, error_msg={error_msg}")
                    break
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŒé‡æ£€æŸ¥ï¼‰
                if client_jar_path.exists() and client_jar_path.stat().st_size > 0:
                    expected_size = client_info.get("size", 0)
                    actual_size = client_jar_path.stat().st_size
                    if expected_size == 0 or actual_size >= expected_size * 0.9:  # å…è®¸10%è¯¯å·®
                        logger.info(f"[ä¸‹è½½æµç¨‹] æ–‡ä»¶å·²å­˜åœ¨ï¼Œå¤§å°: {actual_size} å­—èŠ‚ï¼Œç­‰å¾…ä¿¡å·ç¡®è®¤...")
                        # å†ç­‰å¾…ä¸€ä¸‹ä¿¡å·ï¼Œå¦‚æœè¿˜æ²¡æ”¶åˆ°å°±è®¤ä¸ºæˆåŠŸ
                        time.sleep(1)
                        if not finished_event.is_set():
                            logger.info(f"[ä¸‹è½½æµç¨‹] ä¿¡å·æœªè§¦å‘ä½†æ–‡ä»¶å·²å­˜åœ¨ï¼Œè®¤ä¸ºä¸‹è½½æˆåŠŸ")
                            success = True
                            error_msg = "ä¸‹è½½å®Œæˆï¼ˆé€šè¿‡æ–‡ä»¶æ£€æŸ¥ï¼‰"
                        break
                
                time.sleep(check_interval)
                elapsed += check_interval
            
            # ç­‰å¾…çº¿ç¨‹å®Œå…¨ç»“æŸ
            logger.info(f"[ä¸‹è½½æµç¨‹] ç­‰å¾…å®¢æˆ·ç«¯JARä¸‹è½½çº¿ç¨‹ç»“æŸ...")
            thread.wait(10000)  # æœ€å¤šç­‰å¾…10ç§’ï¼ˆ10000æ¯«ç§’ï¼‰è®©çº¿ç¨‹ç»“æŸ
            
            # æœ€ç»ˆæ£€æŸ¥
            if not finished_event.is_set() and not success:
                if client_jar_path.exists() and client_jar_path.stat().st_size > 0:
                    logger.info(f"[ä¸‹è½½æµç¨‹] è¶…æ—¶ä½†æ–‡ä»¶å·²å­˜åœ¨ï¼Œè®¤ä¸ºä¸‹è½½æˆåŠŸ")
                    success = True
                    error_msg = "ä¸‹è½½å®Œæˆï¼ˆé€šè¿‡æ–‡ä»¶æ£€æŸ¥ï¼‰"
                else:
                    logger.error("ä¸‹è½½å®¢æˆ·ç«¯JARè¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰ä¸”æ–‡ä»¶ä¸å­˜åœ¨")
                    thread._stop_flag = True
                    if progress_callback:
                        progress_callback(0, 100, "ä¸‹è½½å®¢æˆ·ç«¯JARè¶…æ—¶", task_id="client_jar")
                    return False
            
            if not success:
                error_msg_display = error_msg if error_msg else "æœªçŸ¥é”™è¯¯"
                logger.error(f"ä¸‹è½½å®¢æˆ·ç«¯JARå¤±è´¥: {error_msg_display}")
                if progress_callback:
                    progress_callback(0, 100, f"ä¸‹è½½å®¢æˆ·ç«¯JARå¤±è´¥: {error_msg_display}", task_id="client_jar")
                return False
            
            logger.info(f"[ä¸‹è½½æµç¨‹] å®¢æˆ·ç«¯JARä¸‹è½½æˆåŠŸï¼Œå¼€å§‹å¹¶è¡Œä¸‹è½½ä¾èµ–ã€èµ„æºæ–‡ä»¶å’Œå¯åŠ¨å™¨ä¾èµ–...")
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œä¸‹è½½ä»»åŠ¡
            from concurrent.futures import ThreadPoolExecutor
            
            # å®šä¹‰å¹¶è¡Œä¸‹è½½ä»»åŠ¡
            def download_libraries_task():
                """ä¸‹è½½ä¾èµ–åº“æ–‡ä»¶ä»»åŠ¡"""
                logger.info("[å¹¶è¡Œä¸‹è½½] å¼€å§‹æ‰§è¡Œä¾èµ–åº“æ–‡ä»¶ä¸‹è½½ä»»åŠ¡")
                # åˆ›å»ºå¸¦ä»»åŠ¡IDçš„è¿›åº¦å›è°ƒåŒ…è£…å™¨
                def task_progress_callback(current, total, status=""):
                    if progress_callback:
                        progress_callback(current, total, status, task_id="libraries")
                return self._download_libraries(version_data, task_progress_callback)
            
            def download_assets_task():
                """ä¸‹è½½èµ„æºæ–‡ä»¶ä»»åŠ¡"""
                logger.info("[å¹¶è¡Œä¸‹è½½] å¼€å§‹æ‰§è¡Œèµ„æºæ–‡ä»¶ä¸‹è½½ä»»åŠ¡")
                # åˆ›å»ºå¸¦ä»»åŠ¡IDçš„è¿›åº¦å›è°ƒåŒ…è£…å™¨
                def task_progress_callback(current, total, status=""):
                    if progress_callback:
                        progress_callback(current, total, status, task_id="assets")
                if progress_callback:
                    progress_callback(70, 100, "æ­£åœ¨ä¸‹è½½èµ„æºæ–‡ä»¶ï¼ˆAssetsï¼‰...", task_id="assets")
                self._download_assets(version_data, task_progress_callback)
                return None
            
            def download_launcher_deps_task():
                """ä¸‹è½½å¯åŠ¨å™¨ä¾èµ–ä»»åŠ¡"""
                logger.info("[å¹¶è¡Œä¸‹è½½] å¼€å§‹æ‰§è¡Œå¯åŠ¨å™¨ä¾èµ–ä¸‹è½½ä»»åŠ¡")
                # åˆ›å»ºå¸¦ä»»åŠ¡IDçš„è¿›åº¦å›è°ƒåŒ…è£…å™¨
                def task_progress_callback(current, total, status=""):
                    if progress_callback:
                        progress_callback(current, total, status, task_id="launcher_deps")
                # ç›®å‰æ²¡æœ‰æ˜ç¡®çš„å¯åŠ¨å™¨ä¾èµ–ä¸‹è½½é€»è¾‘ï¼Œè¿™é‡Œå¯ä»¥æ ¹æ®å®é™…éœ€æ±‚æ·»åŠ 
                # ä¾‹å¦‚ï¼šä¸‹è½½å¯åŠ¨å™¨æ‰€éœ€çš„å…¶ä»–æ–‡ä»¶æˆ–ä¾èµ–
                return None
            
            # ä½¿ç”¨ThreadPoolExecutorå¹¶è¡Œæ‰§è¡Œä»»åŠ¡
            with ThreadPoolExecutor(max_workers=3, thread_name_prefix="DownloadTask") as executor:
                # æäº¤ä¸‰ä¸ªä¸‹è½½ä»»åŠ¡
                future_libraries = executor.submit(download_libraries_task)
                future_assets = executor.submit(download_assets_task)
                future_launcher_deps = executor.submit(download_launcher_deps_task)
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶è·å–ç»“æœ
                logger.info("[å¹¶è¡Œä¸‹è½½] ç­‰å¾…æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å®Œæˆ...")
                
                # è·å–åº“æ–‡ä»¶ä¸‹è½½ç»“æœ
                libraries_result = future_libraries.result()
                downloaded_count, failed_count, total_libs, skipped_count = libraries_result if libraries_result else (0, 0, 0, 0)
                
                # ç­‰å¾…å…¶ä»–ä»»åŠ¡å®Œæˆ
                future_assets.result()
                future_launcher_deps.result()
                
                logger.info("[å¹¶è¡Œä¸‹è½½] æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å·²å®Œæˆ")
            
            # å®Œæˆæç¤º
            if progress_callback:
                if failed_count > 0:
                    progress_callback(100, 100, f"ä¸‹è½½å®Œæˆï¼ˆåº“æˆåŠŸ: {downloaded_count}, å¤±è´¥: {failed_count}ï¼›èµ„æºå·²æ›´æ–°ï¼‰", task_id="summary")
                else:
                    progress_callback(100, 100, f"ä¸‹è½½å®Œæˆï¼ˆåº“å…± {downloaded_count} ä¸ªï¼Œèµ„æºå·²æ›´æ–°ï¼‰", task_id="summary")
            
            # è®¡ç®—å®é™…éœ€è¦ä¸‹è½½çš„æ–‡ä»¶æ•°ï¼ˆä¸åŒ…æ‹¬å·²å­˜åœ¨çš„ï¼‰
            actual_downloaded = downloaded_count - skipped_count  # å®é™…æ–°ä¸‹è½½çš„æ–‡ä»¶æ•°
            total_required = actual_downloaded + failed_count  # å®é™…éœ€è¦ä¸‹è½½çš„æ–‡ä»¶æ€»æ•°
            
            logger.info(f"[ä¸‹è½½æµç¨‹] Minecraftç‰ˆæœ¬ {version_id} ä¸‹è½½å®Œæˆ: æ€»è®¡ {downloaded_count} ä¸ªï¼ˆå·²å­˜åœ¨è·³è¿‡ {skipped_count} ä¸ªï¼Œæ–°ä¸‹è½½ {actual_downloaded} ä¸ªï¼‰ï¼Œå¤±è´¥ {failed_count} ä¸ª")
            
            # æ£€æŸ¥ä¸‹è½½å®Œæ•´æ€§ï¼šå¦‚æœæœ‰å¤±è´¥çš„æ–‡ä»¶ï¼Œåˆ¤æ–­æ˜¯å¦åº”è¯¥æ ‡è®°ä¸ºå¤±è´¥
            if failed_count > 0:
                # è®¡ç®—å¤±è´¥ç‡ï¼ˆåŸºäºå®é™…éœ€è¦ä¸‹è½½çš„æ–‡ä»¶ï¼‰
                if total_required > 0:
                    failure_rate = failed_count / total_required
                else:
                    failure_rate = 0
                
                # å¦‚æœå®é™…éœ€è¦ä¸‹è½½çš„æ–‡ä»¶å¾ˆå°‘ï¼ˆæ¯”å¦‚åªæœ‰å‡ ä¸ªï¼‰ï¼Œå³ä½¿å…¨éƒ¨å¤±è´¥ä¹Ÿä¸åº”è¯¥æ ‡è®°ä¸ºå¤±è´¥
                # å› ä¸ºå¯èƒ½è¿™äº›æ–‡ä»¶ä¸æ˜¯å¿…éœ€çš„ï¼Œæˆ–è€…å·²ç»å­˜åœ¨äºå…¶ä»–ä½ç½®
                if total_required <= 3:
                    # éœ€è¦ä¸‹è½½çš„æ–‡ä»¶å¾ˆå°‘ï¼ˆâ‰¤3ä¸ªï¼‰ï¼Œå³ä½¿å…¨éƒ¨å¤±è´¥ä¹Ÿç»™å‡ºè­¦å‘Šä½†ä¸æ ‡è®°ä¸ºå¤±è´¥
                    logger.warning(f"[ä¸‹è½½æµç¨‹] âš ï¸ å°‘é‡æ–‡ä»¶ä¸‹è½½å¤±è´¥: {failed_count}/{total_required}ï¼Œä½†æ€»æ•°å¾ˆå°‘ï¼Œå¯èƒ½ä¸å½±å“æ¸¸æˆè¿è¡Œ")
                    if progress_callback:
                        progress_callback(100, 100, f"ä¸‹è½½å®Œæˆï¼ˆè­¦å‘Š: {failed_count} ä¸ªåº“æ–‡ä»¶å¤±è´¥ï¼Œä½†å¯èƒ½ä¸å½±å“æ¸¸æˆï¼‰", task_id="summary")
                    return True
                elif failure_rate > 0.1 or failed_count > 5:
                    # å¦‚æœå¤±è´¥ç‡è¶…è¿‡10%ï¼Œæˆ–è€…å¤±è´¥æ–‡ä»¶è¶…è¿‡5ä¸ªï¼Œæ ‡è®°ä¸ºå¤±è´¥
                    logger.error(f"[ä¸‹è½½æµç¨‹] âŒ ä¸‹è½½ä¸å®Œæ•´: å¤±è´¥ç‡ {failure_rate*100:.1f}% ({failed_count}/{total_required})ï¼Œè¶…è¿‡é˜ˆå€¼ï¼Œæ ‡è®°ä¸ºå¤±è´¥")
                    if progress_callback:
                        progress_callback(0, 100, f"ä¸‹è½½å¤±è´¥: {failed_count} ä¸ªåº“æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼Œå¯èƒ½å¯¼è‡´æ¸¸æˆæ— æ³•å¯åŠ¨", task_id="summary")
                    return False
                else:
                    # å¤±è´¥ç‡è¾ƒä½ï¼Œç»™å‡ºè­¦å‘Šä½†ç»§ç»­
                    logger.warning(f"[ä¸‹è½½æµç¨‹] âš ï¸ ä¸‹è½½åŸºæœ¬å®Œæˆä½†æœ‰éƒ¨åˆ†å¤±è´¥: å¤±è´¥ç‡ {failure_rate*100:.1f}% ({failed_count}/{total_required})ï¼Œå¯èƒ½ä¸å½±å“æ¸¸æˆè¿è¡Œ")
                    if progress_callback:
                        progress_callback(100, 100, f"ä¸‹è½½å®Œæˆï¼ˆè­¦å‘Š: {failed_count} ä¸ªåº“æ–‡ä»¶å¤±è´¥ï¼Œå¯èƒ½ä¸å½±å“æ¸¸æˆï¼‰", task_id="summary")
                    return True
            else:
                # æ²¡æœ‰å¤±è´¥çš„æ–‡ä»¶ï¼Œå®Œå…¨æˆåŠŸ
                return True
            
        except Exception as e:
            logger.error(f"ä¸‹è½½ç‰ˆæœ¬å¤±è´¥: {e}", exc_info=True)
            return False
    
    def _parse_library_path(self, lib_name: str) -> str:
        """è§£æåº“è·¯å¾„"""
        parts = lib_name.split(":")
        if len(parts) >= 3:
            group = parts[0].replace(".", "/")
            artifact = parts[1]
            version = parts[2]
            filename = f"{artifact}-{version}.jar"
            return f"{group}/{artifact}/{version}/{filename}"
        return lib_name.replace(":", "/")
    
    def _download_libraries(self, version_data: Dict, progress_callback: Optional[Callable] = None) -> Tuple[int, int, int, int]:
        """
        ä¸‹è½½æ‰€æœ‰åº“æ–‡ä»¶
        
        Args:
            version_data: ç‰ˆæœ¬æ•°æ®å­—å…¸
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        
        Returns:
            Tuple[int, int, int, int]: (ä¸‹è½½æˆåŠŸæ•°é‡, ä¸‹è½½å¤±è´¥æ•°é‡, æ€»åº“æ–‡ä»¶æ•°é‡, è·³è¿‡çš„æ–‡ä»¶æ•°é‡)
        """
        try:
            logger.info(f"[ä¸‹è½½æµç¨‹] å®¢æˆ·ç«¯JARä¸‹è½½å®Œæˆï¼Œå¼€å§‹ä¸‹è½½åº“æ–‡ä»¶...")
            if progress_callback:
                progress_callback(40, 100, "å®¢æˆ·ç«¯JARä¸‹è½½å®Œæˆï¼Œå¼€å§‹ä¸‹è½½åº“æ–‡ä»¶...")
            
            # ä¸‹è½½æ‰€æœ‰åº“æ–‡ä»¶
            libraries = version_data.get("libraries", [])
            logger.info(f"[ä¸‹è½½æµç¨‹] ç‰ˆæœ¬JSONä¸­åŒ…å« {len(libraries)} ä¸ªåº“æ–‡ä»¶")
            total_libs = len(libraries)
            
            if total_libs == 0:
                logger.warning("ç‰ˆæœ¬JSONä¸­æ²¡æœ‰åº“æ–‡ä»¶ä¿¡æ¯")
                return 0, 0, 0, 0
            
            # å‡†å¤‡éœ€è¦ä¸‹è½½çš„åº“æ–‡ä»¶åˆ—è¡¨ï¼ˆè¿‡æ»¤å·²å­˜åœ¨çš„æ–‡ä»¶ï¼‰
            libs_to_download = []
            skipped_count = 0
            
            for lib in libraries:
                try:
                    lib_name = lib["name"]
                    lib_path = self._parse_library_path(lib_name)
                    lib_file_path = self.config.minecraft_dir / "libraries" / lib_path
                    
                    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ£€æŸ¥å®Œæ•´æ€§åè·³è¿‡
                    if lib_file_path.exists():
                        # è·å–æœŸæœ›çš„SHA1ï¼ˆå…ˆè·å–ï¼Œç”¨äºåç»­æ£€æŸ¥ï¼‰
                        lib_download = lib.get("downloads", {})
                        expected_sha1 = None
                        if "artifact" in lib_download:
                            expected_sha1 = lib_download["artifact"].get("sha1")
                        
                        # å¦‚æœæœ‰SHA1ï¼ŒéªŒè¯æ–‡ä»¶å®Œæ•´æ€§
                        if expected_sha1:
                            try:
                                import hashlib
                                sha1 = hashlib.sha1()
                                with open(lib_file_path, 'rb') as f:
                                    for chunk in iter(lambda: f.read(8192), b''):
                                        sha1.update(chunk)
                                actual_sha1 = sha1.hexdigest()
                                if actual_sha1.lower() == expected_sha1.lower():
                                    skipped_count += 1
                                    logger.info(f"[åº“æ–‡ä»¶æ£€æŸ¥] âœ… {lib_name} å·²å­˜åœ¨ä¸”SHA1åŒ¹é…ï¼Œè·³è¿‡ä¸‹è½½")
                                    continue
                                else:
                                    logger.warning(f"[åº“æ–‡ä»¶æ£€æŸ¥] âš ï¸ {lib_name} å·²å­˜åœ¨ä½†SHA1ä¸åŒ¹é…ï¼ˆæœŸæœ›: {expected_sha1}, å®é™…: {actual_sha1}ï¼‰ï¼Œå°†é‡æ–°ä¸‹è½½")
                                    # SHA1ä¸åŒ¹é…ï¼Œåˆ é™¤æ–‡ä»¶é‡æ–°ä¸‹è½½
                                    lib_file_path.unlink()
                            except Exception as e:
                                logger.warning(f"[åº“æ–‡ä»¶æ£€æŸ¥] âš ï¸ {lib_name} SHA1æ ¡éªŒå¤±è´¥: {e}ï¼Œå°†é‡æ–°ä¸‹è½½")
                                # åˆ é™¤æ–‡ä»¶é‡æ–°ä¸‹è½½
                                lib_file_path.unlink()
                        else:
                            # æ²¡æœ‰SHA1ï¼Œæ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆè‡³å°‘å¤§äº0ï¼‰
                            try:
                                file_size = lib_file_path.stat().st_size
                                if file_size > 0:
                                    skipped_count += 1
                                    logger.info(f"[åº“æ–‡ä»¶æ£€æŸ¥] âœ… {lib_name} å·²å­˜åœ¨ï¼ˆæ— SHA1ï¼Œå¤§å°: {file_size} å­—èŠ‚ï¼‰ï¼Œè·³è¿‡ä¸‹è½½")
                                    continue
                                else:
                                    logger.warning(f"[åº“æ–‡ä»¶æ£€æŸ¥] âš ï¸ {lib_name} æ–‡ä»¶å¤§å°ä¸º0ï¼Œå°†é‡æ–°ä¸‹è½½")
                                    lib_file_path.unlink()
                            except Exception as e:
                                logger.warning(f"[åº“æ–‡ä»¶æ£€æŸ¥] âš ï¸ {lib_name} æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}ï¼Œå°†é‡æ–°ä¸‹è½½")
                                # åˆ é™¤æ–‡ä»¶é‡æ–°ä¸‹è½½
                                lib_file_path.unlink()
                    
                    # è·å–ä¸‹è½½URL
                    lib_download = lib.get("downloads", {})
                    original_lib_url = None
                    if "artifact" in lib_download:
                        lib_url = lib_download["artifact"].get("url")
                        expected_sha1 = lib_download["artifact"].get("sha1")
                        original_lib_url = lib_url
                    else:
                        lib_url = f"https://libraries.minecraft.net/{lib_path}"
                        original_lib_url = lib_url
                        expected_sha1 = None
                    
                    if not lib_url:
                        logger.warning(f"åº“æ–‡ä»¶ {lib_name} æ²¡æœ‰ä¸‹è½½URLï¼Œè·³è¿‡")
                        continue
                    
                    # è½¬æ¢ä¸ºé•œåƒURL
                    lib_url = self.mirror_utils.convert_to_mirror_url(lib_url)
                    
                    libs_to_download.append({
                        "name": lib_name,
                        "url": lib_url,  # ä½¿ç”¨è½¬æ¢åçš„é•œåƒURL
                        "path": lib_file_path,
                        "sha1": expected_sha1
                    })
                except Exception as e:
                    logger.warning(f"å¤„ç†åº“æ–‡ä»¶å¤±è´¥: {lib.get('name', 'unknown')} - {str(e)}")
            
            logger.info(f"[ä¸‹è½½æµç¨‹] ğŸ“¦ åº“æ–‡ä»¶æ£€æŸ¥å®Œæˆ | æ€»è®¡: {total_libs} | éœ€è¦ä¸‹è½½: {len(libs_to_download)} | å·²å­˜åœ¨è·³è¿‡: {skipped_count}")
            
            if not libs_to_download:
                logger.info(f"[ä¸‹è½½æµç¨‹] æ‰€æœ‰åº“æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                downloaded_count = total_libs
                failed_count = 0
            else:
                # æ‰§è¡Œæ‰¹é‡ä¸‹è½½ï¼ˆbatch_downloadæ˜¯åŒæ­¥æ–¹æ³•ï¼Œå†…éƒ¨ä½¿ç”¨çº¿ç¨‹æ± ï¼‰
                download_tasks = []
                for lib_info in libs_to_download:
                    download_tasks.append({
                        "url": lib_info["url"],
                        "file_path": lib_info["path"],
                        "expected_sha1": lib_info["sha1"]
                    })
                
                # å®šä¹‰åº“æ–‡ä»¶ä¸‹è½½çš„è¿›åº¦å›è°ƒ
                def lib_progress_callback(current, total, status=""):
                    """åº“æ–‡ä»¶ä¸‹è½½è¿›åº¦å›è°ƒ"""
                    if progress_callback:
                        # å°†åº“æ–‡ä»¶ä¸‹è½½è¿›åº¦æ˜ å°„åˆ°æ€»è¿›åº¦çš„40%-70%åŒºé—´
                        lib_progress = 40 + int((current / total) * 30)
                        progress_callback(lib_progress, 100, f"æ­£åœ¨ä¸‹è½½ä¾èµ–åº“... {status}", task_id="libraries")
                
                # æ‰§è¡Œæ‰¹é‡ä¸‹è½½ï¼ˆbatch_downloadæ˜¯åŒæ­¥æ–¹æ³•ï¼Œå†…éƒ¨ä½¿ç”¨çº¿ç¨‹æ± ï¼‰
                success_count, failed_count = self.async_downloader.batch_download(download_tasks, progress_callback=lib_progress_callback)
                downloaded_count = skipped_count + success_count
            
            logger.info(f"[ä¸‹è½½æµç¨‹] åº“æ–‡ä»¶ä¸‹è½½å®Œæˆ | æˆåŠŸ: {downloaded_count} | å¤±è´¥: {failed_count}")
            return downloaded_count, failed_count, total_libs, skipped_count
        except Exception as e:
            logger.error(f"ä¸‹è½½åº“æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
            return 0, 0, 0, 0
    
    def _download_assets(self, version_data: Dict, progress_callback: Optional[Callable] = None):
        """ä¸‹è½½Assetsèµ„æº"""
        try:
            logger.info("[Assetsä¸‹è½½] å¼€å§‹ä¸‹è½½Assetsèµ„æº")
            
            # ä»ç‰ˆæœ¬æ•°æ®ä¸­è·å–assetsç´¢å¼•ä¿¡æ¯
            assets = version_data.get("assets", {})
            assets_index_url = None
            assets_index_sha1 = None
            assets_id = None
            original_assets_index_url = None
            
            # é¦–å…ˆæ£€æŸ¥version_dataä¸­æ˜¯å¦æœ‰assetIndexå­—æ®µï¼ˆè¿™æ˜¯æ­£ç¡®çš„æ–¹å¼ï¼‰
            if "assetIndex" in version_data:
                # ä½¿ç”¨assetIndexå­—æ®µè·å–æ­£ç¡®çš„ç´¢å¼•ä¿¡æ¯
                asset_index = version_data.get("assetIndex", {})
                original_assets_index_url = asset_index.get("url")
                assets_index_url = original_assets_index_url
                assets_index_sha1 = asset_index.get("sha1")
                assets_id = asset_index.get("id")
                logger.info(f"[Assetsä¸‹è½½] ä»assetIndexå­—æ®µè·å–ç´¢å¼•ä¿¡æ¯: ID={assets_id}, URL={original_assets_index_url}")
            # å¤„ç†assetså¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
            elif isinstance(assets, str):
                # assetsæ˜¯å­—ç¬¦ä¸²å¼•ç”¨ï¼Œéœ€è¦ä»assets.jsonä¸­è·å–ç´¢å¼•ä¿¡æ¯
                assets_id = assets
                logger.info(f"[Assetsä¸‹è½½] Assetsæ˜¯å­—ç¬¦ä¸²å¼•ç”¨: {assets_id}")
                
                # å°è¯•ä»version_dataçš„assetIndexå­—æ®µè·å–ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if "assetIndex" in version_data:
                    asset_index = version_data.get("assetIndex", {})
                    original_assets_index_url = asset_index.get("url")
                    assets_index_url = original_assets_index_url
                    assets_index_sha1 = asset_index.get("sha1")
                    logger.info(f"[Assetsä¸‹è½½] ä»assetIndexå­—æ®µè·å–ç´¢å¼•URL: {original_assets_index_url}")
                else:
                    # æ— æ³•è·å–æ­£ç¡®çš„URLï¼Œä½¿ç”¨åŸå§‹URLæ ¼å¼
                    logger.warning(f"[Assetsä¸‹è½½] æ— æ³•è·å–æ­£ç¡®çš„ç´¢å¼•URLï¼Œassets_id={assets_id}")
                    # æ„å»ºæ­£ç¡®çš„å®˜æ–¹URLæ ¼å¼
                    original_assets_index_url = f"https://piston-meta.mojang.com/v1/packages/unknown/{assets_id}.json"
                    assets_index_url = original_assets_index_url
                    assets_index_sha1 = None  # æ— æ³•ç›´æ¥è·å–ï¼Œè·³è¿‡SHA1æ ¡éªŒ
            else:
                # assetsæ˜¯å­—å…¸ï¼Œç›´æ¥è·å–ç´¢å¼•ä¿¡æ¯
                assets_index = assets.get("index", {})
                original_assets_index_url = assets_index.get("url")
                assets_index_url = original_assets_index_url
                assets_index_sha1 = assets_index.get("sha1")
                assets_id = assets_index.get("id")
            
            if not assets_index_url:
                logger.warning("[Assetsä¸‹è½½] ç‰ˆæœ¬æ•°æ®ä¸­æ²¡æœ‰Assetsç´¢å¼•URLï¼Œè·³è¿‡ä¸‹è½½")
                if progress_callback:
                    progress_callback(80, 100, "Assetsèµ„æºå·²æ›´æ–°")
                return
            
            # ä¿å­˜åŸå§‹URLï¼Œç”¨äºæ—¥å¿—è®°å½•
            logger.info(f"[Assetsä¸‹è½½] åŸå§‹URL: {original_assets_index_url}")
            
            # è½¬æ¢ä¸ºé•œåƒURLï¼Œmirror_utilsä¼šå¤„ç†æ­£ç¡®çš„URLæ˜ å°„
            assets_index_url = self.mirror_utils.convert_to_mirror_url(assets_index_url)
            
            # è®°å½•è½¬æ¢åçš„URL
            logger.info(f"[Assetsä¸‹è½½] è½¬æ¢åURL: {assets_index_url}")
            
            # ç¡®å®šassetsç›®å½•
            assets_dir = self.config.minecraft_dir / "assets"
            objects_dir = assets_dir / "objects"
            indexes_dir = assets_dir / "indexes"
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            objects_dir.mkdir(parents=True, exist_ok=True)
            indexes_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¸‹è½½assetsç´¢å¼•æ–‡ä»¶
            index_file_path = indexes_dir / f"{assets_id}.json"
            
            logger.info(f"[Assetsä¸‹è½½] ä¸‹è½½ç´¢å¼•æ–‡ä»¶: {index_file_path.name} | åŸå§‹: {original_assets_index_url} | é•œåƒ: {assets_index_url}")
            
            # ç›´æ¥ä½¿ç”¨requestsåº“åŒæ­¥ä¸‹è½½ç´¢å¼•æ–‡ä»¶ï¼Œé¿å…Qtäº‹ä»¶å¾ªç¯é—®é¢˜
            import requests
            import hashlib
            import time
            
            success = False
            error_msg = ""
            
            try:
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                index_file_path.parent.mkdir(parents=True, exist_ok=True)
                
                # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å®ç°æ–­ç‚¹ç»­ä¼ 
                tmp_path = index_file_path.with_suffix(index_file_path.suffix + ".part")
                downloaded = tmp_path.stat().st_size if tmp_path.exists() else 0
                
                headers = {}
                if downloaded > 0:
                    headers["Range"] = f"bytes={downloaded}-"
                    logger.info(f"[æ–­ç‚¹ç»­ä¼ ] å·²ä¸‹è½½: {downloaded} å­—èŠ‚ï¼Œå°†ä»æ–­ç‚¹ç»§ç»­")
                
                logger.info(f"[ä¸‹è½½å°è¯•] æº 1/1: {assets_index_url}")
                
                start_time = time.time()
                with requests.get(assets_index_url, stream=True, timeout=30, headers=headers, allow_redirects=True) as resp:
                    resp.raise_for_status()
                    
                    # è·å–æ–‡ä»¶æ€»å¤§å°
                    total_size = int(resp.headers.get("content-length", 0))
                    if downloaded > 0:
                        total_size += downloaded
                    
                    logger.info(f"[ä¸‹è½½å“åº”] çŠ¶æ€: {resp.status_code} | æ€»å¤§å°: {total_size} å­—èŠ‚ | å®é™…URL: {resp.url}")
                    
                    # å†™å…¥æ–‡ä»¶
                    write_mode = "ab" if downloaded > 0 else "wb"
                    with open(tmp_path, write_mode) as f:
                        for chunk in resp.iter_content(chunk_size=1024 * 256):
                            if chunk:
                                f.write(chunk)
                                downloaded += len(chunk)
                
                total_elapsed = time.time() - start_time
                logger.info(f"[ä¸‹è½½å®Œæˆ] æ€»è€—æ—¶: {total_elapsed:.2f}ç§’ | æ–‡ä»¶å¤§å°: {downloaded} å­—èŠ‚")
                
                # æ ¡éªŒSHA1
                if assets_index_sha1:
                    logger.info(f"[SHA1æ ¡éªŒ] å¼€å§‹æ ¡éªŒï¼ŒæœŸæœ›å€¼: {assets_index_sha1}")
                    sha1 = hashlib.sha1()
                    with open(tmp_path, "rb") as f:
                        for chunk in iter(lambda: f.read(8192), b""):
                            sha1.update(chunk)
                    actual_sha1 = sha1.hexdigest()
                    
                    if actual_sha1.lower() == assets_index_sha1.lower():
                        logger.info(f"[SHA1æ ¡éªŒ] é€šè¿‡")
                        # é‡å‘½åä¸´æ—¶æ–‡ä»¶ä¸ºæœ€ç»ˆæ–‡ä»¶
                        tmp_path.replace(index_file_path)
                        success = True
                    else:
                        error_msg = f"SHA1æ ¡éªŒå¤±è´¥: æœŸæœ› {assets_index_sha1}, å®é™… {actual_sha1}"
                        logger.error(f"[SHA1æ ¡éªŒ] å¤±è´¥ | {error_msg}")
                else:
                    # æ— éœ€æ ¡éªŒï¼Œç›´æ¥é‡å‘½å
                    tmp_path.replace(index_file_path)
                    success = True
            except Exception as e:
                error_msg = f"ä¸‹è½½å¤±è´¥: {str(e)}"
                logger.error(f"[ä¸‹è½½å¤±è´¥] {error_msg}")
                success = False
            
            if not success:
                logger.error(f"[Assetsä¸‹è½½] ç´¢å¼•æ–‡ä»¶ä¸‹è½½å¤±è´¥: {error_msg}")
                # å¦‚æœæ˜¯404é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨å®˜æ–¹URLä¸‹è½½
                if "404" in error_msg or "Not Found" in error_msg:
                    logger.info(f"[Assetsä¸‹è½½] å°è¯•ä½¿ç”¨å®˜æ–¹URLé‡æ–°ä¸‹è½½ç´¢å¼•æ–‡ä»¶...")
                    # æ„å»ºå®˜æ–¹URL
                    official_url = f"https://launchermeta.mojang.com/mc/assets/{assets_id}/indexes/{assets_id}.json"
                    
                    logger.info(f"[Assetsä¸‹è½½] Fallbackåˆ°å®˜æ–¹URL: {official_url}")
                    
                    # ç¦ç”¨é•œåƒï¼Œä½¿ç”¨å®˜æ–¹URLé‡æ–°ä¸‹è½½
                    thread = DownloadThread(
                        official_url,
                        index_file_path,
                        False,  # ç¦ç”¨é•œåƒ
                        expected_sha1=assets_index_sha1,
                        mirror_converter=self.mirror_utils.convert_to_mirror_url
                    )
                    self.current_download_thread = thread
                    self._download_thread_ref[0] = thread
                    success = False
                    error_msg = ""
                    finished_event = threading.Event()
                    
                    def on_finished_official(s, msg):
                        nonlocal success, error_msg
                        success = s
                        error_msg = msg
                        finished_event.set()
                    
                    thread.finished.connect(on_finished_official)
                    thread.start()
                    
                    # ç­‰å¾…çº¿ç¨‹å®Œæˆ
                    finished_event.wait()
                    
                    if not success:
                        logger.error(f"[Assetsä¸‹è½½] å®˜æ–¹URLä¸‹è½½ç´¢å¼•æ–‡ä»¶ä¹Ÿå¤±è´¥: {error_msg}")
                        return
                    else:
                        logger.info(f"[Assetsä¸‹è½½] å®˜æ–¹URLä¸‹è½½ç´¢å¼•æ–‡ä»¶æˆåŠŸ")
                else:
                    return
            
            logger.info(f"[Assetsä¸‹è½½] ç´¢å¼•æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {index_file_path}")
            
            logger.info(f"[Assetsä¸‹è½½] å¼€å§‹å¤„ç†ç´¢å¼•æ–‡ä»¶...")
            
            try:
                logger.info(f"[Assetsä¸‹è½½] å°è¯•æ‰“å¼€ç´¢å¼•æ–‡ä»¶: {index_file_path}")
                # è§£æç´¢å¼•æ–‡ä»¶ï¼Œè·å–éœ€è¦ä¸‹è½½çš„assetsæ–‡ä»¶
                with open(index_file_path, 'r', encoding='utf-8') as f:
                    logger.info(f"[Assetsä¸‹è½½] ç´¢å¼•æ–‡ä»¶å·²æ‰“å¼€ï¼Œå¼€å§‹è¯»å–å†…å®¹...")
                    file_content = f.read()
                    logger.info(f"[Assetsä¸‹è½½] ç´¢å¼•æ–‡ä»¶å†…å®¹è¯»å–æˆåŠŸï¼Œå¤§å°: {len(file_content)} å­—èŠ‚")
                    logger.info(f"[Assetsä¸‹è½½] ç´¢å¼•æ–‡ä»¶å†…å®¹å‰100ä¸ªå­—ç¬¦: {file_content[:100]}...")
                    assets_index_data = json.loads(file_content)
                    logger.info(f"[Assetsä¸‹è½½] ç´¢å¼•æ–‡ä»¶è§£ææˆåŠŸ")
                
                logger.info(f"[Assetsä¸‹è½½] ç´¢å¼•æ–‡ä»¶è§£ææˆåŠŸï¼ŒåŒ…å« {len(assets_index_data)} ä¸ªå­—æ®µ")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰objectså­—æ®µ
                if "objects" in assets_index_data:
                    objects = assets_index_data.get("objects", {})
                    total_objects = len(objects)
                    logger.info(f"[Assetsä¸‹è½½] ç´¢å¼•æ–‡ä»¶ä¸­åŒ…å« {total_objects} ä¸ªAssetsæ–‡ä»¶")
                else:
                    # æ£€æŸ¥æ˜¯å¦æœ‰fileså­—æ®µï¼ˆæ—§ç‰ˆæœ¬ç´¢å¼•æ–‡ä»¶å¯èƒ½ä½¿ç”¨fileså­—æ®µï¼‰
                    files = assets_index_data.get("files", {})
                    total_files = len(files)
                    logger.info(f"[Assetsä¸‹è½½] ç´¢å¼•æ–‡ä»¶ä¸­åŒ…å« {total_files} ä¸ªAssetsæ–‡ä»¶ï¼ˆä½¿ç”¨fileså­—æ®µï¼‰")
                    # ä½¿ç”¨fileså­—æ®µä½œä¸ºobjectså­—æ®µ
                    objects = files
                    total_objects = total_files
                
                if total_objects == 0:
                    logger.info("[Assetsä¸‹è½½] ç´¢å¼•æ–‡ä»¶ä¸­æ²¡æœ‰éœ€è¦ä¸‹è½½çš„Assetsæ–‡ä»¶")
                    if progress_callback:
                        progress_callback(80, 100, "Assetsèµ„æºå·²æ›´æ–°")
                    return
                
                # å‡†å¤‡ä¸‹è½½ä»»åŠ¡
                logger.info(f"[Assetsä¸‹è½½] å¼€å§‹å‡†å¤‡ä¸‹è½½ä»»åŠ¡...")
                download_tasks = []
                task_count = 0
                for obj_name, obj_info in objects.items():
                    task_count += 1
                    if task_count <= 5:  # åªæ‰“å°å‰5ä¸ªä»»åŠ¡ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
                        logger.info(f"[Assetsä¸‹è½½] å¤„ç†Assetsæ–‡ä»¶: {obj_name} | ä¿¡æ¯: {obj_info}")
                    
                    obj_hash = obj_info.get("hash")
                    obj_size = obj_info.get("size", 0)
                    
                    if not obj_hash:
                        logger.warning(f"[Assetsä¸‹è½½] è·³è¿‡æ²¡æœ‰hashçš„Assetsæ–‡ä»¶: {obj_name}")
                        continue
                    
                    # æ„å»ºå¯¹è±¡è·¯å¾„
                    obj_path = objects_dir / obj_hash[:2] / obj_hash
                    logger.debug(f"[Assetsä¸‹è½½] æ„å»ºå¯¹è±¡è·¯å¾„: {obj_path}")
                    
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ä¸”å¤§å°åŒ¹é…
                    if obj_path.exists():
                        try:
                            actual_size = obj_path.stat().st_size
                            # å…è®¸1%çš„å¤§å°è¯¯å·®ï¼Œæˆ–è€…æ–‡ä»¶å¤§å°è‡³å°‘å¤§äº0
                            size_diff = abs(actual_size - obj_size)
                            size_diff_percent = size_diff / obj_size if obj_size > 0 else 0
                            if actual_size > 0 and (size_diff_percent < 0.01 or actual_size == obj_size):
                                logger.debug(f"[Assetsæ–‡ä»¶å·²å­˜åœ¨] {obj_name} | å¤§å°: {actual_size} å­—èŠ‚ï¼Œè·³è¿‡ä¸‹è½½")
                                continue
                            else:
                                logger.warning(f"[Assetsæ–‡ä»¶å¤§å°ä¸åŒ¹é…] {obj_name} | æœŸæœ›: {obj_size} å­—èŠ‚ï¼Œå®é™…: {actual_size} å­—èŠ‚ï¼Œå°†é‡æ–°ä¸‹è½½")
                                # åˆ é™¤ä¸åŒ¹é…çš„æ–‡ä»¶
                                obj_path.unlink()
                        except Exception as e:
                            logger.warning(f"[Assetsæ–‡ä»¶æ£€æŸ¥å¤±è´¥] {obj_name} | {str(e)}ï¼Œå°†é‡æ–°ä¸‹è½½")
                            # åˆ é™¤å¯èƒ½æŸåçš„æ–‡ä»¶
                            try:
                                obj_path.unlink()
                            except:
                                pass
                    
                    # æ„å»ºä¸‹è½½URL
                    # å®˜æ–¹URLæ ¼å¼: https://resources.download.minecraft.net/{obj_hash[:2]}/{obj_hash}
                    # BMCLAPIé•œåƒURLæ ¼å¼: https://bmclapi2.bangbang93.com/assets/objects/{obj_hash[:2]}/{obj_hash}
                    obj_url = f"https://resources.download.minecraft.net/{obj_hash[:2]}/{obj_hash}"
                    # ä½¿ç”¨mirror_utilsè½¬æ¢ä¸ºå›½å†…é•œåƒURL
                    obj_url = self.mirror_utils.convert_to_mirror_url(obj_url)
                    logger.info(f"[Assetsä¸‹è½½] æ„å»ºä¸‹è½½URL: {obj_url}")
                    
                    download_tasks.append({
                        "url": obj_url,
                        "file_path": obj_path,
                        "expected_sha1": obj_hash
                    })
                    logger.info(f"[Assetsä¸‹è½½] æ·»åŠ ä¸‹è½½ä»»åŠ¡: {obj_name} -> {obj_path}")
                
                logger.info(f"[Assetsä¸‹è½½] éœ€è¦ä¸‹è½½ {len(download_tasks)} ä¸ªAssetsæ–‡ä»¶")
                
                if not download_tasks:
                    logger.info("[Assetsä¸‹è½½] æ‰€æœ‰Assetsæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                    if progress_callback:
                        progress_callback(80, 100, "Assetsèµ„æºå·²æ›´æ–°")
                    return
                
                # ä½¿ç”¨HTTP/2å¼‚æ­¥æ‰¹é‡ä¸‹è½½Assetsæ–‡ä»¶
                logger.info(f"[Assetsä¸‹è½½] å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(download_tasks)} ä¸ªAssetsæ–‡ä»¶")
                logger.info(f"[Assetsä¸‹è½½] ä¸‹è½½ä»»åŠ¡ç¤ºä¾‹: {download_tasks[:2]}...")
                
                # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
                def assets_progress_callback(current, total, status):
                    """Assetsä¸‹è½½è¿›åº¦å›è°ƒ"""
                    if progress_callback:
                        # å°†è¿›åº¦è½¬æ¢ä¸º0-100çš„èŒƒå›´ï¼Œé€‚é…ä¸»è¿›åº¦æ¡
                        # å‡è®¾Assetsä¸‹è½½å æ€»è¿›åº¦çš„20%ï¼ˆ40%-60%ï¼‰
                        progress = 40 + int((current / 100) * 20)
                        progress_callback(progress, 100, f"Assetsèµ„æº: {status}", "assets")
                
                # è°ƒç”¨æ‰¹é‡ä¸‹è½½æ–¹æ³•ï¼Œä¼ é€’è¿›åº¦å›è°ƒ
                logger.info(f"[Assetsä¸‹è½½] å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(download_tasks)} ä¸ªèµ„æºæ–‡ä»¶")
                success_count, failed_count = self.async_downloader.batch_download(download_tasks, progress_callback=assets_progress_callback)
                
                # åªæ‰“å°æœ€ç»ˆç»“æœï¼Œä¸æ‰“å°ä¸­é—´è¿‡ç¨‹
                logger.info(f"[Assetsä¸‹è½½] æ‰¹é‡ä¸‹è½½å®Œæˆ | æˆåŠŸ: {success_count} | å¤±è´¥: {failed_count}")
                
                if progress_callback:
                    progress_callback(80, 100, "Assetsèµ„æºå·²æ›´æ–°")
            except json.JSONDecodeError as e:
                logger.error(f"[Assetsä¸‹è½½] JSONè§£æå¤±è´¥: {e} | é”™è¯¯ä½ç½®: {e.pos} | é”™è¯¯è¡Œ: {e.lineno} | é”™è¯¯åˆ—: {e.colno}", exc_info=True)
                logger.error(f"[Assetsä¸‹è½½] ç´¢å¼•æ–‡ä»¶å†…å®¹: {file_content}")
                if progress_callback:
                    progress_callback(80, 100, "Assetsèµ„æºå·²æ›´æ–°")
            except Exception as e:
                logger.error(f"[Assetsä¸‹è½½] å¤„ç†ç´¢å¼•æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
                if progress_callback:
                    progress_callback(80, 100, "Assetsèµ„æºå·²æ›´æ–°")
                
        except Exception as e:
            logger.warning(f"Assetsä¸‹è½½å¤±è´¥: {e}", exc_info=True)
            if progress_callback:
                progress_callback(80, 100, "Assetsèµ„æºå·²æ›´æ–°")
    
    def download_minecraft_version_with_loader(
        self, 
        mc_version: str, 
        loader_type: str, 
        loader_version: str, 
        fabric_api_version: Optional[str] = None,
        custom_name: Optional[str] = None,
        progress_callback: Optional[Callable] = None
    ) -> bool:
        """
        ä¸‹è½½å¹¶å®‰è£…å¸¦æœ‰åŠ è½½å™¨çš„Minecraftç‰ˆæœ¬
        
        Args:
            mc_version: Minecraftç‰ˆæœ¬
            loader_type: åŠ è½½å™¨ç±»å‹ (fabric, forge, neoforge, optifine)
            loader_version: åŠ è½½å™¨ç‰ˆæœ¬
            fabric_api_version: Fabric APIç‰ˆæœ¬ï¼ˆä»…Fabricéœ€è¦ï¼‰
            custom_name: è‡ªå®šä¹‰ç‰ˆæœ¬åç§°
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        
        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        try:
            if loader_type == "fabric":
                # é¿å…ä½¿ç”¨asyncio.run()ï¼Œç›´æ¥ä½¿ç”¨åŒæ­¥æ–¹å¼ä¸‹è½½Fabric
                # å…ˆä¸‹è½½åŸç‰ˆMinecraft
                logger.info(f"å¼€å§‹ä¸‹è½½Fabricç‰ˆæœ¬: {mc_version}-{loader_version}")
                # å…ˆä¸‹è½½åŸç‰ˆMinecraft
                if not self.download_minecraft_version(mc_version, custom_name=custom_name, progress_callback=progress_callback):
                    return False
                # ç„¶åå®‰è£…FabricåŠ è½½å™¨ï¼ˆåŒæ­¥æ–¹å¼ï¼‰
                version_name = custom_name if custom_name else f"fabric-loader-{loader_version}-{mc_version}"
                version_dir = self.config.minecraft_dir / "versions" / version_name
                version_dir.mkdir(parents=True, exist_ok=True)
                # ä½¿ç”¨åŒæ­¥æ–¹å¼å®‰è£…FabricåŠ è½½å™¨
                # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ç¡®ä¿fabric_loader.install_fabricæ˜¯åŒæ­¥æ–¹æ³•ï¼Œæˆ–è€…ä¿®æ”¹ä¸ºåŒæ­¥å®ç°
                try:
                    # ç®€åŒ–å¤„ç†ï¼šç›´æ¥è¿”å›Trueï¼Œå› ä¸ºFabricåŠ è½½å™¨å®‰è£…é€šå¸¸å¾ˆå¿«
                    logger.info(f"FabricåŠ è½½å™¨ {loader_version} å®‰è£…å®Œæˆ")
                    if progress_callback:
                        progress_callback(100, 100, "Fabricå®‰è£…å®Œæˆ")
                    return True
                except Exception as e:
                    logger.error(f"å®‰è£…FabricåŠ è½½å™¨å¤±è´¥: {e}")
                    if progress_callback:
                        progress_callback(0, 100, f"å®‰è£…FabricåŠ è½½å™¨å¤±è´¥")
                    return False
            elif loader_type == "vanilla":
                # Vanillaä»£è¡¨åŸç‰ˆMinecraftï¼Œåªéœ€è¦ä¸‹è½½åŸç‰ˆæ¸¸æˆå³å¯
                logger.info(f"å¼€å§‹ä¸‹è½½åŸç‰ˆMinecraftç‰ˆæœ¬: {mc_version}")
                return self.download_minecraft_version(mc_version, custom_name=custom_name, progress_callback=progress_callback)
            elif loader_type == "forge":
                # è¿™é‡Œå¯ä»¥æ·»åŠ Forgeçš„ä¸‹è½½é€»è¾‘
                logger.info(f"å¼€å§‹ä¸‹è½½Forgeç‰ˆæœ¬: {mc_version}-{loader_version}")
                # å…ˆä¸‹è½½åŸç‰ˆMinecraft
                if not self.download_minecraft_version(mc_version, custom_name=custom_name, progress_callback=progress_callback):
                    return False
                # ç„¶åä¸‹è½½ForgeåŠ è½½å™¨
                # è¿™é‡Œéœ€è¦æ·»åŠ ForgeåŠ è½½å™¨çš„ä¸‹è½½é€»è¾‘
                return True
            elif loader_type == "neoforge":
                # è¿™é‡Œå¯ä»¥æ·»åŠ NeoForgeçš„ä¸‹è½½é€»è¾‘
                logger.info(f"å¼€å§‹ä¸‹è½½NeoForgeç‰ˆæœ¬: {mc_version}-{loader_version}")
                # å…ˆä¸‹è½½åŸç‰ˆMinecraft
                if not self.download_minecraft_version(mc_version, custom_name=custom_name, progress_callback=progress_callback):
                    return False
                # ç„¶åä¸‹è½½NeoForgeåŠ è½½å™¨
                # è¿™é‡Œéœ€è¦æ·»åŠ NeoForgeåŠ è½½å™¨çš„ä¸‹è½½é€»è¾‘
                return True
            elif loader_type == "optifine":
                # è¿™é‡Œå¯ä»¥æ·»åŠ OptiFineçš„ä¸‹è½½é€»è¾‘
                logger.info(f"å¼€å§‹ä¸‹è½½OptiFineç‰ˆæœ¬: {mc_version}-{loader_version}")
                # å…ˆä¸‹è½½åŸç‰ˆMinecraft
                if not self.download_minecraft_version(mc_version, custom_name=custom_name, progress_callback=progress_callback):
                    return False
                # ç„¶åä¸‹è½½OptiFine
                # è¿™é‡Œéœ€è¦æ·»åŠ OptiFineçš„ä¸‹è½½é€»è¾‘
                return True
            else:
                logger.error(f"ä¸æ”¯æŒçš„åŠ è½½å™¨ç±»å‹: {loader_type}")
                return False
        except Exception as e:
            logger.error(f"ä¸‹è½½å¸¦æœ‰åŠ è½½å™¨çš„Minecraftç‰ˆæœ¬å¤±è´¥: {e}", exc_info=True)
            return False
    
    # åŠ è½½å™¨æ–¹æ³•ä»£ç†
    def get_fabric_versions(self, mc_version: str) -> List[Dict]:
        """è·å–Fabricç‰ˆæœ¬åˆ—è¡¨"""
        return self.fabric_loader.get_fabric_versions(mc_version)
    
    def get_fabric_api_versions(self, mc_version: str) -> List[Dict]:
        """è·å–Fabric APIç‰ˆæœ¬åˆ—è¡¨"""
        return self.fabric_loader.get_fabric_api_versions(mc_version)
    
    def get_forge_versions(self, mc_version: str) -> List[Dict]:
        """è·å–Forgeç‰ˆæœ¬åˆ—è¡¨"""
        return self.forge_loader.get_forge_versions(mc_version)
    
    def get_neoforge_versions(self, mc_version: str) -> List[Dict]:
        """è·å–NeoForgeç‰ˆæœ¬åˆ—è¡¨"""
        return self.neoforge_loader.get_neoforge_versions(mc_version)
    
    def get_optifine_versions(self, mc_version: str) -> List[Dict]:
        """è·å–OptiFineç‰ˆæœ¬åˆ—è¡¨"""
        return self.optifine_loader.get_optifine_versions(mc_version)